{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02113a2a",
   "metadata": {},
   "source": [
    "# 1. layer and block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5bca3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/Atari/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38fdc8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2647,  0.1254,  0.0784, -0.0398, -0.1507, -0.0325, -0.2295,  0.0818,\n",
       "         -0.2620, -0.3462],\n",
       "        [ 0.1897,  0.1873,  0.2611, -0.1057, -0.2237,  0.1050, -0.2661,  0.0588,\n",
       "         -0.2029, -0.2887]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df188d0",
   "metadata": {},
   "source": [
    "## 1.1 自定义块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b50f009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a80650f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "504c8885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2363,  0.0557, -0.0316,  0.0048, -0.1877,  0.0591,  0.0633,  0.1861,\n",
       "          0.1684,  0.0116],\n",
       "        [-0.1220, -0.0128, -0.2427,  0.0213, -0.3506,  0.0814, -0.0737,  0.2226,\n",
       "          0.0656, -0.1820]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf43482",
   "metadata": {},
   "source": [
    "## 1.2 Sequential\n",
    "\n",
    "自定义的sequential，实现和sequential 相同的 功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e718c0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0239,  0.0338,  0.2586, -0.0771,  0.1172,  0.1354, -0.0220, -0.1866,\n",
       "          0.1070,  0.1103],\n",
       "        [-0.0342, -0.0453,  0.3676, -0.1687,  0.0667,  0.0856, -0.0581, -0.1386,\n",
       "          0.1124,  0.1119]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for block in args:\n",
    "            self._modules[block] = block\n",
    "            \n",
    "    def forward(self, X):\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X\n",
    "    \n",
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "net(X)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf37f43a",
   "metadata": {},
   "source": [
    "## 1.3 在正向传播中执行代码\n",
    "\n",
    "这个例子想要说明，我们可以通过继承module的方法做更自由的代码实现\n",
    "\n",
    "尤其是forward的过程，我们可以添加很多自己想要的实现\n",
    "\n",
    "举个例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a910bd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.4288, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        X = self.linear(X)\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()\n",
    "    \n",
    "net = FixedHiddenMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ff2537",
   "metadata": {},
   "source": [
    "## 1.4 混合搭配各种组合module\n",
    "\n",
    "感觉像在搭积木"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "322d6e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1289, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n",
    "                                nn.Linear(64, 32), nn.ReLU())\n",
    "        \n",
    "        self.linear = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "    \n",
    "chimera = nn.Sequential(NestMLP(), nn.Linear(10, 20), FixedHiddenMLP())\n",
    "chimera(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14f3f48",
   "metadata": {},
   "source": [
    "# 2. 参数管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b9f0bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5018],\n",
       "        [-0.4941]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b01229",
   "metadata": {},
   "source": [
    "## 2.1 参数管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d017fcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[-0.2869, -0.3520, -0.0393,  0.0051, -0.1816,  0.1800, -0.2032, -0.1351]])), ('bias', tensor([-0.0825]))])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].state_dict()) # 最后一层的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc971a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.0825], requires_grad=True)\n",
      "tensor([-0.0825])\n"
     ]
    }
   ],
   "source": [
    "print(type(net[2].bias))\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1d9738e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.grad == None # 拿到对应的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "905e304e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4, out_features=8, bias=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d3907cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight', torch.Size([8, 4])), ('bias', torch.Size([8]))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, param.shape) for name, param in net[0].named_parameters()] # 拿到对应的参数名字以及形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edb7a3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.weight', torch.Size([8, 4])),\n",
       " ('0.bias', torch.Size([8])),\n",
       " ('2.weight', torch.Size([1, 8])),\n",
       " ('2.bias', torch.Size([1]))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, param.shape) for name, param in net.named_parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33834963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0825])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['2.bias'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ba4f92",
   "metadata": {},
   "source": [
    "## 2.2 嵌套块收集参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0230f5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5172],\n",
       "        [-0.5170]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 4))\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        net.add_module(f'block {i}', block1()) # 添加的时候，给个名字\n",
    "        \n",
    "    return net\n",
    "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
    "rgnet(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3c0faeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (block 0): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "    )\n",
       "    (block 1): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "    )\n",
       "    (block 2): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "    )\n",
       "    (block 3): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb331a",
   "metadata": {},
   "source": [
    "## 2.3 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39297ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0038,  0.0145,  0.0095, -0.0103]), tensor(0.))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        # nn.init 中包含很多相关的初始化函数\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "        \n",
    "net.apply(init_normal)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ace82071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff9cf84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0552,  0.0269, -0.5893,  0.1143])\n",
      "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "def xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "def init_42(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 42)\n",
    "        \n",
    "net[0].apply(xavier)\n",
    "net[2].apply(init_42)\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46cf0ef",
   "metadata": {},
   "source": [
    "## 2.4 自定义初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb1360bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init:  weight torch.Size([8, 4])\n",
      "init:  weight torch.Size([1, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 6.7864,  0.0000,  9.0977, -9.7963],\n",
       "        [-5.9737,  0.0000, -0.0000, -0.0000],\n",
       "        [ 5.0594, -5.7662,  7.5889, -0.0000],\n",
       "        [-0.0000,  5.4502, -5.9764, -6.8746],\n",
       "        [-6.2652,  5.8229, -8.1528,  5.2202],\n",
       "        [-8.0869,  0.0000,  5.8413,  7.0939],\n",
       "        [-0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0000,  0.0000,  7.1868,  0.0000]], requires_grad=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        print(\"init: \",\n",
    "             *[(name, param.shape) for name, param in m.named_parameters()][0])\n",
    "        \n",
    "        nn.init.uniform_(m.weight, -10, 10)\n",
    "        # 将绝对值 大于5的 取出来\n",
    "        m.weight.data *= m.weight.data.abs() >= 5\n",
    "        \n",
    "net.apply(my_init)\n",
    "net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a89ba5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42.0000,  1.0000, 10.0977, -8.7963])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 更暴力的初始化方法，直接获取net中的weight，对其进行设置\n",
    "\n",
    "net[0].weight.data[:] += 1\n",
    "net[0].weight.data[0, 0] = 42\n",
    "net[0].weight.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767de084",
   "metadata": {},
   "source": [
    "## 2.5 参数绑定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "594949bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0715, -0.1623, -0.0285,  0.3051],\n",
       "        [-0.0740, -0.1606, -0.0318,  0.3066]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared = nn.Linear(8, 8)\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), shared, nn.ReLU(), shared, nn.ReLU(), nn.Linear(8, 4))\n",
    "\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38ec065f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "974555c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(100.)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].weight.data[0,0] = 100\n",
    "net[4].weight.data[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dd7caa",
   "metadata": {},
   "source": [
    "# 3. 自定义层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e4ac0e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CenterLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X - X.mean()\n",
    "    \n",
    "layer = CenterLayer()\n",
    "layer(torch.FloatTensor([1,2,3,4,5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b0486",
   "metadata": {},
   "source": [
    "## 3.1 将自定义层作为组建放到model中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4473f8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3283e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 没有任何区别，跟正常使用\n",
    "net = nn.Sequential(nn.Linear(8, 16), CenterLayer())\n",
    "\n",
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bb2ef0",
   "metadata": {},
   "source": [
    "## 3.2 带参数的图层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7cc93ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, out_units):\n",
    "        super().__init__()\n",
    "        # 所有加梯度加名字的地方\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, out_units))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_units))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        linear = torch.matmul(X , self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98c5f0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.8259,  0.3679,  0.9901],\n",
       "        [-1.0777, -0.9172,  0.7317],\n",
       "        [-1.7821,  1.0496,  1.6881],\n",
       "        [-1.3052, -0.4197, -0.9922],\n",
       "        [ 0.0969, -0.3633,  0.7659]], requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = MyLinear(5, 3)\n",
    "dense.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc7aa128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weight', torch.Size([5, 3])), ('bias', torch.Size([3]))]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x, y.shape) for x, y in dense.named_parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d6e505",
   "metadata": {},
   "source": [
    "# 4. 读写文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead01940",
   "metadata": {},
   "source": [
    "## 4.1 加载和保存单个张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4243c2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "torch.save(x, './models/x-file')\n",
    "\n",
    "x2 = torch.load('./models/x-file')\n",
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec061c",
   "metadata": {},
   "source": [
    "## 4.2 加载和保存list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a9f29e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.zeros(3)\n",
    "torch.save([x, y], './models/list-file')\n",
    "\n",
    "x2, y2 = torch.load('./models/list-file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bfbaabd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0.]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2, y2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb3e90e",
   "metadata": {},
   "source": [
    "## 4.3 加载和保存字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67a3e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = {'x':x, 'y': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e5b4f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "torch.save(mydict, './models/dict_file')\n",
    "mydict2 = torch.load('./models/dict_file')\n",
    "print(mydict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b27b56",
   "metadata": {},
   "source": [
    "## 4.4 加载和保存模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1c99ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.output(F.relu(self.hidden(X)))\n",
    "    \n",
    "net = MLP()\n",
    "X = torch.randn(size=(10, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "310b84df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f856718",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'models/mlp_param')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d146b470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('models/mlp_param'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04020948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "24c83813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
